{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jcZQVnmtTQ0"
      },
      "source": [
        "# Danish Rahadian Mirza Effendi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqQiYqborIOe"
      },
      "source": [
        "## Rock, Paper, Scissors Image Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH4cLS24rIOg"
      },
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "m64Q8OQCrIOh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import zipfile\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpig\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !wget --no-check-certificate \\\n",
        "#   https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extract Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dir = \"dataset/rockpaperscissors.zip\"\n",
        "# zip = zipfile.ZipFile(dir, 'r')\n",
        "# zip.extractall(\"dataset\")\n",
        "# zip.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxAHGStKrIOk"
      },
      "source": [
        "### Making Base Diractory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "dgHSC0rgrIOk"
      },
      "outputs": [],
      "source": [
        "base_dir = \"dataset/rockpaperscissors/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70BrDwU-rIOl"
      },
      "source": [
        "### Check Diractory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKXgb-c8rIOl",
        "outputId": "4a6a97fd-97fe-48d7-9939-7e7eeaf80ff3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['paper', 'README_rpc-cv-images.txt', 'rock', 'scissors']"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir(base_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzYLOVTurIOl"
      },
      "source": [
        "### Check Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CSuJkbdrIOl",
        "outputId": "a684594e-4c65-4b2d-9cbe-6095f2a53b5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rock images: 1690\n",
            "Paper images: 1676\n",
            "Scissors images: 1714\n"
          ]
        }
      ],
      "source": [
        "rock_dir = os.path.join(base_dir, \"rock\")\n",
        "paper_dir = os.path.join(base_dir, \"paper\")\n",
        "scissors_dir = os.path.join(base_dir, \"scissors\")\n",
        "\n",
        "print(f\"Rock images: {len(os.listdir(rock_dir))}\")\n",
        "print(f\"Paper images: {len(os.listdir(paper_dir))}\")\n",
        "print(f\"Scissors images: {len(os.listdir(scissors_dir))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrHusN7crIOm"
      },
      "source": [
        "### Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "dcRwgcUJrIOm"
      },
      "outputs": [],
      "source": [
        "generator = ImageDataGenerator(\n",
        "    rescale = 1/255,\n",
        "    rotation_range = 20,\n",
        "    horizontal_flip = True,\n",
        "    shear_range = 0.2,\n",
        "    fill_mode = \"wrap\",\n",
        "    validation_split = 0.4\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7It2tfswrIOm"
      },
      "source": [
        "### Separate Train and Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thRpoyM2rIOm",
        "outputId": "c1d20078-0fa9-469f-bc1a-49cc659bd9eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3049 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "train_gen = generator.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size =(100,150),\n",
        "    batch_size = 32,\n",
        "    class_mode = \"categorical\",\n",
        "    subset = \"training\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4P9A8GurIOn",
        "outputId": "7479ef00-acdc-4663-af95-3ea3bc78e90e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2031 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "val_gen = generator.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size = (100,150),\n",
        "    batch_size = 32,\n",
        "    class_mode = \"categorical\",\n",
        "    subset = \"validation\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'paper': 0, 'rock': 1, 'scissors': 2}\n",
            "{'paper': 0, 'rock': 1, 'scissors': 2}\n"
          ]
        }
      ],
      "source": [
        "print(train_gen.class_indices)\n",
        "print(val_gen.class_indices)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xB2VGWq6rIOn"
      },
      "source": [
        "### Build the Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "w5gyksdGrIOn"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "layer = tf.keras.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "j9sMW_JzrIOo"
      },
      "outputs": [],
      "source": [
        "# First Layer\n",
        "model.add(layer.Conv2D(32, (3,3), activation=\"relu\", input_shape=(100,150,3)))\n",
        "model.add(layer.MaxPooling2D(2,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "BcMSSUIurIOo"
      },
      "outputs": [],
      "source": [
        "# Second Layer\n",
        "model.add(layer.Conv2D(64, (3,3), activation=\"relu\"))\n",
        "model.add(layer.MaxPool2D(2,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "H02E1ZufrIOo"
      },
      "outputs": [],
      "source": [
        "# Third Layer\n",
        "model.add(layer.Conv2D(128, (3,3), activation=\"relu\"))\n",
        "model.add(layer.MaxPool2D(2,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "tB5EOWZVrIOo"
      },
      "outputs": [],
      "source": [
        "# Fourth Layer\n",
        "model.add(layer.Conv2D(128, (3,3), activation=\"relu\"))\n",
        "model.add(layer.MaxPool2D(2,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "ZLvGAAPurIOo"
      },
      "outputs": [],
      "source": [
        "# Flattening\n",
        "model.add(layer.Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "p25fcRMmrIOp"
      },
      "outputs": [],
      "source": [
        "# Full Conection\n",
        "model.add(layer.Dense(512, activation=\"relu\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "dIVQTDoPrIOp"
      },
      "outputs": [],
      "source": [
        "# Output Layer\n",
        "model.add(layer.Dense(3, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdUexnsErIOp",
        "outputId": "9969aecf-e66a-411c-c23b-438323aabcff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_20 (Conv2D)          (None, 98, 148, 32)       896       \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPooli  (None, 49, 74, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 47, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPooli  (None, 23, 36, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 21, 34, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPooli  (None, 10, 17, 128)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 8, 15, 128)        147584    \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPooli  (None, 4, 7, 128)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 3584)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 512)               1835520   \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 3)                 1539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2077891 (7.93 MB)\n",
            "Trainable params: 2077891 (7.93 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Model Summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lghg3p0WrIOp"
      },
      "source": [
        "### Compiling Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "5iNkjGYvrIOq"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=RMSprop(), metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq4-jmk4rIOq"
      },
      "source": [
        "### Train Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDXxely8rIOq",
        "outputId": "88817c7c-fbd9-4d1f-b101-b1582d695b19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "25/25 - 11s - loss: 1.1185 - accuracy: 0.3562 - val_loss: 1.0941 - val_accuracy: 0.3750 - 11s/epoch - 423ms/step\n",
            "Epoch 2/25\n",
            "25/25 - 8s - loss: 0.9199 - accuracy: 0.5713 - val_loss: 0.9173 - val_accuracy: 0.5625 - 8s/epoch - 327ms/step\n",
            "Epoch 3/25\n",
            "25/25 - 8s - loss: 0.7724 - accuracy: 0.7713 - val_loss: 0.9477 - val_accuracy: 0.4437 - 8s/epoch - 331ms/step\n",
            "Epoch 4/25\n",
            "25/25 - 8s - loss: 0.6074 - accuracy: 0.7875 - val_loss: 0.7989 - val_accuracy: 0.5688 - 8s/epoch - 316ms/step\n",
            "Epoch 5/25\n",
            "25/25 - 8s - loss: 0.2866 - accuracy: 0.8975 - val_loss: 1.0646 - val_accuracy: 0.5312 - 8s/epoch - 317ms/step\n",
            "Epoch 6/25\n",
            "25/25 - 8s - loss: 0.3656 - accuracy: 0.8750 - val_loss: 0.6996 - val_accuracy: 0.6062 - 8s/epoch - 315ms/step\n",
            "Epoch 7/25\n",
            "25/25 - 8s - loss: 0.2095 - accuracy: 0.9228 - val_loss: 0.8730 - val_accuracy: 0.5625 - 8s/epoch - 308ms/step\n",
            "Epoch 8/25\n",
            "25/25 - 8s - loss: 0.2419 - accuracy: 0.9162 - val_loss: 0.5871 - val_accuracy: 0.7750 - 8s/epoch - 315ms/step\n",
            "Epoch 9/25\n",
            "25/25 - 8s - loss: 0.2343 - accuracy: 0.9150 - val_loss: 0.6006 - val_accuracy: 0.7250 - 8s/epoch - 318ms/step\n",
            "Epoch 10/25\n",
            "25/25 - 8s - loss: 0.1167 - accuracy: 0.9563 - val_loss: 0.8734 - val_accuracy: 0.6000 - 8s/epoch - 312ms/step\n",
            "Epoch 11/25\n",
            "25/25 - 8s - loss: 0.1738 - accuracy: 0.9275 - val_loss: 0.5422 - val_accuracy: 0.6875 - 8s/epoch - 316ms/step\n",
            "Epoch 12/25\n",
            "25/25 - 8s - loss: 0.1429 - accuracy: 0.9450 - val_loss: 0.6254 - val_accuracy: 0.7688 - 8s/epoch - 321ms/step\n",
            "Epoch 13/25\n",
            "25/25 - 8s - loss: 0.1190 - accuracy: 0.9537 - val_loss: 0.6410 - val_accuracy: 0.7000 - 8s/epoch - 322ms/step\n",
            "Epoch 14/25\n",
            "25/25 - 9s - loss: 0.0916 - accuracy: 0.9625 - val_loss: 0.4825 - val_accuracy: 0.8250 - 9s/epoch - 375ms/step\n",
            "Epoch 15/25\n",
            "25/25 - 9s - loss: 0.1145 - accuracy: 0.9562 - val_loss: 0.6286 - val_accuracy: 0.7375 - 9s/epoch - 371ms/step\n",
            "Epoch 16/25\n",
            "25/25 - 9s - loss: 0.2123 - accuracy: 0.9375 - val_loss: 0.7231 - val_accuracy: 0.6125 - 9s/epoch - 378ms/step\n",
            "Epoch 17/25\n",
            "25/25 - 9s - loss: 0.0695 - accuracy: 0.9700 - val_loss: 0.3863 - val_accuracy: 0.8500 - 9s/epoch - 380ms/step\n",
            "Epoch 18/25\n",
            "25/25 - 10s - loss: 0.0605 - accuracy: 0.9812 - val_loss: 0.4193 - val_accuracy: 0.8125 - 10s/epoch - 389ms/step\n",
            "Epoch 19/25\n",
            "25/25 - 10s - loss: 0.1078 - accuracy: 0.9665 - val_loss: 0.5208 - val_accuracy: 0.8125 - 10s/epoch - 391ms/step\n",
            "Epoch 20/25\n",
            "25/25 - 10s - loss: 0.0549 - accuracy: 0.9800 - val_loss: 0.4791 - val_accuracy: 0.8500 - 10s/epoch - 380ms/step\n",
            "Epoch 21/25\n",
            "25/25 - 9s - loss: 0.0880 - accuracy: 0.9737 - val_loss: 0.2222 - val_accuracy: 0.9125 - 9s/epoch - 378ms/step\n",
            "Epoch 22/25\n",
            "25/25 - 9s - loss: 0.0568 - accuracy: 0.9837 - val_loss: 0.6776 - val_accuracy: 0.7000 - 9s/epoch - 377ms/step\n",
            "Epoch 23/25\n",
            "25/25 - 9s - loss: 0.0361 - accuracy: 0.9887 - val_loss: 0.7173 - val_accuracy: 0.7437 - 9s/epoch - 379ms/step\n",
            "Epoch 24/25\n",
            "25/25 - 9s - loss: 0.0555 - accuracy: 0.9787 - val_loss: 0.4565 - val_accuracy: 0.7937 - 9s/epoch - 377ms/step\n",
            "Epoch 25/25\n",
            "25/25 - 10s - loss: 0.0762 - accuracy: 0.9750 - val_loss: 0.3442 - val_accuracy: 0.8813 - 10s/epoch - 381ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x16c29f68950>"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_gen, steps_per_epoch= 25, epochs=25, validation_data= val_gen, validation_steps= 5, verbose= 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model/saved_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model/saved_model\\assets\n"
          ]
        }
      ],
      "source": [
        "model.save('model/saved_model')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
